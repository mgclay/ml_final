{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1595d58",
   "metadata": {},
   "source": [
    "TRAIN STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "eb86d623-e91b-489b-8c0c-2cbbafcad945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from imblearn.over_sampling import SMOTE, ADASYN\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "STOP = [ 'stop', 'the', 'to', 'and', 'a', 'in', 'it', 'is', 'I', 'that', 'had', 'on', 'for', 'were', 'was']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "f3873c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'between', 'any', 'then', 'shan', 'isn', 'because', 'own', 'this', 'other', 's', 're', \"mustn't\", 'its', 'has', 'he', 'on', 'some', 'now', 'just', 'why', 'than', 'so', 'have', 'been', 'for', 'whom', 'herself', \"shan't\", 'each', 'about', 'out', 'very', 'him', \"hadn't\", 'her', 'nor', 'that', \"shouldn't\", 'up', 't', 'until', 'are', 'doesn', 'ain', 'couldn', 'm', 'my', \"you're\", \"wasn't\", 'such', 'into', 'be', 'what', 'no', 'most', 'hadn', 'his', \"she's\", 'hers', \"weren't\", 'i', 'o', 'ours', 'had', 'theirs', \"aren't\", 'down', 'if', 'below', 'few', 'or', 'it', 'when', 'too', 'didn', \"hasn't\", 'your', 'wasn', 'doing', 'not', 'd', 'itself', \"haven't\", 'll', 'but', 'will', \"doesn't\", 'during', 'they', 'through', 'who', \"couldn't\", 'was', \"mightn't\", \"you'd\", 'more', 'she', \"should've\", 'you', 'of', 'hasn', \"don't\", 'themselves', 'we', 'the', 'against', 'after', 'in', \"wouldn't\", 'yours', 'and', 'again', 'an', 'from', 'shouldn', 've', 'yourselves', \"needn't\", 'ourselves', 'haven', \"didn't\", 'where', 'won', \"you'll\", 'me', 'can', 'yourself', \"won't\", 'these', 'before', 'being', 'wouldn', 'there', 'which', 'both', 'y', 'were', \"it's\", 'over', 'should', 'same', 'at', 'ma', 'only', 'himself', 'off', 'those', 'don', 'aren', 'needn', 'weren', 'mustn', 'is', 'myself', 'their', 'here', 'mightn', 'our', \"that'll\", \"isn't\", 'to', 'as', 'under', 'did', \"you've\", 'them', 'a', 'how', 'by', 'further', 'all', 'do', 'am', 'having', 'once', 'with', 'above', 'does', 'while'}\n"
     ]
    }
   ],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "print(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "d7342578-120e-4f45-aa01-cdd4e1891ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = pd.read_csv('train_with_label.txt', sep = '\\t', \\\n",
    "                              names = ['instance_id', 'sentence1', 'sentence2', 'label'], \\\n",
    "                             quoting = 3)\n",
    "\n",
    "train_df = pd.DataFrame(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "fdc8aa76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_id</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_id_0</td>\n",
       "      <td>Is it in the food supply ? \" says David Ropeik...</td>\n",
       "      <td>The pound also made progress against the dolla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_id_1</td>\n",
       "      <td>Hundreds of soldiers were involved , an appare...</td>\n",
       "      <td>Avants , wearing a light brown jumpsuit , had ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_id_2</td>\n",
       "      <td>And Sen. Michael Crapo , R-Idaho , chairman of...</td>\n",
       "      <td>. 's Kempthorne of friend longtime a is , nomi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_id_3</td>\n",
       "      <td>The gunman , 26-year-old Harold Kilpatrick jnr...</td>\n",
       "      <td>\" In fact , I was physically sick several time...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_id_4</td>\n",
       "      <td>The League of United Latin American Citizens ,...</td>\n",
       "      <td>No. 2 HP saw its Unix server sales dropped 3.6...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7796</th>\n",
       "      <td>train_id_7796</td>\n",
       "      <td>Toll last week offered to buy the company for ...</td>\n",
       "      <td>Toll , Australia 's second-largest transport c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7797</th>\n",
       "      <td>train_id_7797</td>\n",
       "      <td>Experts say they think better treatment , incl...</td>\n",
       "      <td>Experts say they think better treatment , incl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7798</th>\n",
       "      <td>train_id_7798</td>\n",
       "      <td>The Dow Jones industrial average &lt; .DJI &gt; rose...</td>\n",
       "      <td>. 8,949.00 to , percent 1.12 or , points 98.74...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7799</th>\n",
       "      <td>train_id_7799</td>\n",
       "      <td>In Sweden , 99 percent of women are literate ,...</td>\n",
       "      <td>In Sweden , 99 percent of women are literate w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7800</th>\n",
       "      <td>train_id_7800</td>\n",
       "      <td>Tornadoes , up to a foot of rain and hail as b...</td>\n",
       "      <td>. homes four least at destroying and man one k...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7801 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        instance_id                                          sentence1  \\\n",
       "0        train_id_0  Is it in the food supply ? \" says David Ropeik...   \n",
       "1        train_id_1  Hundreds of soldiers were involved , an appare...   \n",
       "2        train_id_2  And Sen. Michael Crapo , R-Idaho , chairman of...   \n",
       "3        train_id_3  The gunman , 26-year-old Harold Kilpatrick jnr...   \n",
       "4        train_id_4  The League of United Latin American Citizens ,...   \n",
       "...             ...                                                ...   \n",
       "7796  train_id_7796  Toll last week offered to buy the company for ...   \n",
       "7797  train_id_7797  Experts say they think better treatment , incl...   \n",
       "7798  train_id_7798  The Dow Jones industrial average < .DJI > rose...   \n",
       "7799  train_id_7799  In Sweden , 99 percent of women are literate ,...   \n",
       "7800  train_id_7800  Tornadoes , up to a foot of rain and hail as b...   \n",
       "\n",
       "                                              sentence2  label  \n",
       "0     The pound also made progress against the dolla...      0  \n",
       "1     Avants , wearing a light brown jumpsuit , had ...      0  \n",
       "2     . 's Kempthorne of friend longtime a is , nomi...      0  \n",
       "3     \" In fact , I was physically sick several time...      0  \n",
       "4     No. 2 HP saw its Unix server sales dropped 3.6...      0  \n",
       "...                                                 ...    ...  \n",
       "7796  Toll , Australia 's second-largest transport c...      1  \n",
       "7797  Experts say they think better treatment , incl...      0  \n",
       "7798  . 8,949.00 to , percent 1.12 or , points 98.74...      0  \n",
       "7799  In Sweden , 99 percent of women are literate w...      1  \n",
       "7800  . homes four least at destroying and man one k...      0  \n",
       "\n",
       "[7801 rows x 4 columns]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "3e8b0c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df):\n",
    "    sent1 = df.loc[:, 'sentence1']\n",
    "    sent2 = df.loc[:, 'sentence2']\n",
    "    labels = df.loc[:, 'label']\n",
    "    \n",
    "    return sent1, sent2, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "a59b12f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sent1, train_sent2, train_labels = get_data(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "id": "bb21cbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = stopwords.words('english')\n",
    "STOPWORDS = set(STOPWORDS)\n",
    "    \n",
    "def text_prepare(text, STOPWORDS):\n",
    "    REPLACE_BY_SPACE_RE = re.compile('[\\n\\\"\\'/(){}\\[\\]\\|@,;#]')\n",
    "    text = re.sub(REPLACE_BY_SPACE_RE, ' ', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    #rx =  re.compile('[\\n\\'()\\w]+|\\.]')\n",
    "    #text = re.sub(rx, ' ', text)\n",
    "    #text = re.sub(' +', ' ', text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # delete stopwords from text\n",
    "    text = ' '.join([word for word in text.split() if word not in STOP]) \n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "id": "b9e32907",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokall1 = []\n",
    "tokall2 = []\n",
    "for i in range(len(train_df)):\n",
    "    tok1 = ''\n",
    "    tok2 = ''\n",
    "    tok1 = text_prepare(train_sent1[i], STOP)\n",
    "    tok2 = text_prepare(train_sent2[i], STOP)\n",
    "    tokall1.append(tok1)\n",
    "    tokall2.append(tok2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "id": "9198d33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['food supply ? says david ropeik director of risk communication at harvard center risk analysis .',\n",
       " 'hundreds of soldiers involved an apparent signal hamas israel would not limit itself air strikes gaza .',\n",
       " 'sen. michael crapo r-idaho chairman of subcommittee first will take up nomination longtime friend of kempthorne s .',\n",
       " 'gunman 26-year-old harold kilpatrick jnr left note saying he wanted kill some people die today .',\n",
       " 'league of united latin american citizens group criticizing schwarzenegger said austrian-born actor s advisory board position brings into question his commitment hispanics .',\n",
       " 'jan. 12 1996 two of his nude models arrested atop of manhattan snowdrift posed beneath an ice-cream parlor sign advertised frozen fantasies .',\n",
       " 'bush administration blames hussein loyalists foreign muslim militants who have entered iraq fight u.s. troops wave of bombings guerrilla attacks .',\n",
       " 'if this escalation continues as rowling concludes saga there may be an epidemic of hogwarts headaches years come .',\n",
       " 'hispanics have officially overtaken african americans as largest minority group us according report released by us census bureau .',\n",
       " 'rudolph ate here joked sign outside one restaurant .',\n",
       " 'massachusetts attorney general tom reilly did not let judge s penny-pinching get him down .',\n",
       " 'spitzer among group of federal state regulators who negotiated $ 1.4 billion settlement with 10 brokerage houses settle investigations of analyst conflicts of interest .',\n",
       " 'runners are often injured by bulls 13 have been killed since 1900 .',\n",
       " 'crossing jordan will be back january after star jill hennessy gives birth .',\n",
       " 'authorities baylor officials say dennehy 21 hasn t been heard from more than two weeks .',\n",
       " 'variable annuity sales $ 4.2 billion 82 percent higher than year ago .',\n",
       " 'another chechen emergency ministry official ruslan khadzhiyev said truck carrying equivalent of 1.6 tons of tnt .',\n",
       " 'if s sunday night before comdex must be time yet another bill gates keynote .',\n",
       " 'he also said tom siebel turned 26 million stock options with value of $ 54 million $ 56 million earlier this year .',\n",
       " 'still pinellas rabies cases fell sharply 17 1996 3 1997 agnew said .',\n",
       " 'short workers worse hearing than expected by age -- three times more often than taller workers writes barrenas .',\n",
       " 'stocks surged tuesday as economic reports pointed thriving housing market an uptick consumer confidence .',\n",
       " 'academy will get its own internal report next week will be made public rosa said .',\n",
       " 'emily church london bureau chief of cbs.marketwatch.com.',\n",
       " 'you have dig deep come up with goods against guys are out there competing with best of us .',\n",
       " 'li deputy chairman of cheung kong holdings ltd . < 0001.hk > .',\n",
       " 'magistrates searched tanzi s home near parma wednesday tried question him same day only find he left italy an undisclosed foreign country .',\n",
       " 'mta will not discuss matter because of pending litigation .',\n",
       " 'but gelinas says only six have been fully re-evaluated .',\n",
       " 'there s no reason you keep your skills up u.s. district judge j. frederick motz told mcgriff after he sentenced .']"
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokall1[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "id": "06bb0901",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzz_similarity = []\n",
    "for i in range(len(tokall1)):\n",
    "    ratio = fuzz.ratio(tokall1[i], tokall2[i])\n",
    "    fuzz_similarity += [ratio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "43e8873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_df=0.9, min_df=5, token_pattern='(\\S+)', analyzer='char')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "ece07500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#toktotal1 = [item for s in tokall1 for item in s]\n",
    "#toktotal2 = [item for s in tokall2 for item in s]\n",
    "\n",
    "tokevery = []\n",
    "#tokevery = toktotal1 + toktotal2\n",
    "\n",
    "for i in range(len(tokall1)):\n",
    "    tokevery.append(tokall1[i])\n",
    "    tokevery.append(tokall2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "79ef6ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = tfidf.fit_transform(tokevery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "49990a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15602"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "16d92963",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidflist1 = []\n",
    "tfidflist2 = []\n",
    "for i in range(len(tokall1)):\n",
    "    tfidflist1 += tfidf.transform([tokall1[i]])\n",
    "    tfidflist2 += tfidf.transform([tokall2[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "dfa0790b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<1x47 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 9 stored elements in Compressed Sparse Row format>,\n",
       " <1x47 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 14 stored elements in Compressed Sparse Row format>,\n",
       " <1x47 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 9 stored elements in Compressed Sparse Row format>,\n",
       " <1x47 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 13 stored elements in Compressed Sparse Row format>,\n",
       " <1x47 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 9 stored elements in Compressed Sparse Row format>]"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidflist[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "105c32f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokevery = []\n",
    "#for i in range(len(tokall1)):\n",
    "    #train_all = []\n",
    "   # train_all.append(tokall1[i])\n",
    "   # train_all.append(tokall2[i])\n",
    "    \n",
    "    #tokevery.append(dev_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "d9c3c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_tfidf = []\n",
    "#for i in range(len(tokevery)):\n",
    "  #  train_tfidf.append(tfidf.transform([tokevery[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "cd47ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_similarity= []\n",
    "for i in range(len(tfidflist1)):\n",
    "    similarity = cosine_similarity(tfidflist1[i], tfidflist2[i]).flatten()\n",
    "    train_similarity.append(similarity.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "21445348",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_similarity = [i.tolist() for i in train_similarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "4795a0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_similarity_int = []\n",
    "for i in range(len(train_similarity)):\n",
    "    train_similarity_int.append(train_similarity[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c2c6cf",
   "metadata": {},
   "source": [
    "DEV STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "472bfe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_sentences = pd.read_csv('dev_with_label.txt', sep = '\\t', \\\n",
    "                              names = ['instance_id', 'sentence1', 'sentence2', 'label'], \\\n",
    "                             quoting = 3)\n",
    "\n",
    "dev_df = pd.DataFrame(dev_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "79548c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_id</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev_id_0</td>\n",
       "      <td>He said he did not think that the Shenzhou V l...</td>\n",
       "      <td>He said he did not think that the Shenzhou V l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev_id_1</td>\n",
       "      <td>Under NASD regulations , Mr. Young can file a ...</td>\n",
       "      <td>Josephine Burke , who ran the unlicensed dayca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dev_id_2</td>\n",
       "      <td>In Europe , France 's CAC-40 rose 0.6 percent ...</td>\n",
       "      <td>IBM shares closed up $ 1.75 , or 2.11 percent ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dev_id_3</td>\n",
       "      <td>Schroeder cancelled his Italian holiday after ...</td>\n",
       "      <td>Schroeder cancelled his Italian holiday after ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dev_id_4</td>\n",
       "      <td>U.S. District Judge William Barbour said he im...</td>\n",
       "      <td>Federal Judge William Barbour said Tuesday he ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>dev_id_3995</td>\n",
       "      <td>Authorities said the bodies of a man and woman...</td>\n",
       "      <td>When asked where the weapons were , Rice said ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>dev_id_3996</td>\n",
       "      <td>The most common side effects after getting the...</td>\n",
       "      <td>Common side effects include nasal congestion ,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>dev_id_3997</td>\n",
       "      <td>Russian cosmonaut Malenchenko achieved a first...</td>\n",
       "      <td>It even struck a deal for distribution and adv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>dev_id_3998</td>\n",
       "      <td>Maddox , who had battled cancer since 1983 , c...</td>\n",
       "      <td>Maddox , 87 , cracked two ribs when he fell ab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>dev_id_3999</td>\n",
       "      <td>She appeared in federal court there Monday and...</td>\n",
       "      <td>\" It 's obvious I 'm not riding as well as yea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      instance_id                                          sentence1  \\\n",
       "0        dev_id_0  He said he did not think that the Shenzhou V l...   \n",
       "1        dev_id_1  Under NASD regulations , Mr. Young can file a ...   \n",
       "2        dev_id_2  In Europe , France 's CAC-40 rose 0.6 percent ...   \n",
       "3        dev_id_3  Schroeder cancelled his Italian holiday after ...   \n",
       "4        dev_id_4  U.S. District Judge William Barbour said he im...   \n",
       "...           ...                                                ...   \n",
       "3995  dev_id_3995  Authorities said the bodies of a man and woman...   \n",
       "3996  dev_id_3996  The most common side effects after getting the...   \n",
       "3997  dev_id_3997  Russian cosmonaut Malenchenko achieved a first...   \n",
       "3998  dev_id_3998  Maddox , who had battled cancer since 1983 , c...   \n",
       "3999  dev_id_3999  She appeared in federal court there Monday and...   \n",
       "\n",
       "                                              sentence2  label  \n",
       "0     He said he did not think that the Shenzhou V l...      0  \n",
       "1     Josephine Burke , who ran the unlicensed dayca...      0  \n",
       "2     IBM shares closed up $ 1.75 , or 2.11 percent ...      0  \n",
       "3     Schroeder cancelled his Italian holiday after ...      0  \n",
       "4     Federal Judge William Barbour said Tuesday he ...      1  \n",
       "...                                                 ...    ...  \n",
       "3995  When asked where the weapons were , Rice said ...      0  \n",
       "3996  Common side effects include nasal congestion ,...      1  \n",
       "3997  It even struck a deal for distribution and adv...      0  \n",
       "3998  Maddox , 87 , cracked two ribs when he fell ab...      1  \n",
       "3999  \" It 's obvious I 'm not riding as well as yea...      0  \n",
       "\n",
       "[4000 rows x 4 columns]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "e3757afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_sent1, dev_sent2, dev_labels = get_data(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "25984e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_tokall1 = []\n",
    "dev_tokall2 = []\n",
    "for i in range(len(dev_df)):\n",
    "    dev_tok1 = ''\n",
    "    dev_tok2 = ''\n",
    "    dev_tok1 = text_prepare(dev_sent1[i], STOPWORDS)\n",
    "    dev_tok2 = text_prepare(dev_sent2[i], STOPWORDS)\n",
    "    dev_tokall1.append(dev_tok1)\n",
    "    dev_tokall2.append(dev_tok2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "a5bcc600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#toktotal1 = [item for s in tokall1 for item in s]\n",
    "#toktotal2 = [item for s in tokall2 for item in s]\n",
    "\n",
    "dev_tokevery = []\n",
    "#tokevery = toktotal1 + toktotal2\n",
    "\n",
    "for i in range(len(dev_tokall1)):\n",
    "    dev_tokevery.append(dev_tokall1[i])\n",
    "    dev_tokevery.append(dev_tokall2[i])\n",
    "    \n",
    "#for i in range(len(dev_tokall1)):\n",
    " #   dev_all = []\n",
    "  #  dev_all.append(dev_tokall1[i])\n",
    "  #  dev_all.append(dev_tokall2[i])\n",
    "    \n",
    "   # dev_tokevery.append(dev_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "id": "c1cbae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_fuzz_similarity = []\n",
    "for i in range(len(dev_tokall1)):\n",
    "    ratio = fuzz.ratio(dev_tokall1[i], dev_tokall2[i])\n",
    "    dev_fuzz_similarity +=[ratio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "0c559388",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_tfidf1 = []\n",
    "dev_tfidf2 = []\n",
    "for i in range(len(dev_tokall1)):\n",
    "    dev_tfidf1 += tfidf.transform(dev_tokall1[i])\n",
    "    dev_tfidf2 += tfidf.transform(dev_tokall2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "500c9268",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_similarity=[]\n",
    "for i in range(len(dev_tfidf1)):\n",
    "    similarity = cosine_similarity(dev_tfidf1[i], dev_tfidf2[i]).flatten()\n",
    "    dev_similarity.append(similarity.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "id": "ed74ccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzz_similarity = [[i] for i in fuzz_similarity]\n",
    "dev_fuzz_similarity = [[i] for i in dev_fuzz_similarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "a97a29c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_similarity = [i.tolist() for i in dev_similarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "040225eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_similarity_int = []\n",
    "for i in range(len(dev_similarity)):\n",
    "    dev_similarity_int.append(dev_similarity[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "id": "428964c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_MLP(train_features, test_features, train_targets, test_targets):\n",
    "    classifier = MLPClassifier(hidden_layer_sizes=(15,), verbose=10, activation='relu', batch_size=100, solver='adam', max_iter=300, learning_rate_init=0.0009)\n",
    "    classifier.fit(train_features, train_targets)\n",
    "    predictions = classifier.predict(test_features)\n",
    "    print(predictions)\n",
    "    score = f1_score(test_targets, predictions)\n",
    "    accuracy = accuracy_score(test_targets, predictions)\n",
    "    print(score)\n",
    "    print(accuracy)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "id": "c84446aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = list(train_labels)\n",
    "dev_labels = list(dev_labels)\n",
    "\n",
    "for i in range(len(dev_labels)):\n",
    "    try:\n",
    "        dev_labels[i] = int(dev_labels[i])\n",
    "    except:\n",
    "        dev_labels[i] = 0\n",
    "        \n",
    "for i in range(len(train_labels)):\n",
    "    try:\n",
    "        train_labels[i] = int(train_labels[i])\n",
    "    except:\n",
    "        train_labels[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "id": "27a71916",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stuff = pd.DataFrame({'similarity': fuzz_similarity, 'gold_label': train_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "id": "e09b71c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(fuzz_similarity)):\n",
    "    fuzz_similarity[i] = 10 * fuzz_similarity[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "id": "65125dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dev_fuzz_similarity)):\n",
    "    dev_fuzz_similarity[i] = 10 * dev_fuzz_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9180a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = build_MLP(fuzz_similarity, dev_fuzz_similarity, train_labels, dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "id": "e82f1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "id": "19810be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0\n",
       "0   1\n",
       "1   0\n",
       "2   0\n",
       "3   0\n",
       "4   0\n",
       "5   0\n",
       "6   1\n",
       "7   0\n",
       "8   0\n",
       "9   0\n",
       "10  0\n",
       "11  0\n",
       "12  0\n",
       "13  0\n",
       "14  0\n",
       "15  0\n",
       "16  0\n",
       "17  0\n",
       "18  1\n",
       "19  0\n",
       "20  0\n",
       "21  0\n",
       "22  1\n",
       "23  0\n",
       "24  1\n",
       "25  0\n",
       "26  0\n",
       "27  1\n",
       "28  0\n",
       "29  0\n",
       "30  0\n",
       "31  0\n",
       "32  0\n",
       "33  0\n",
       "34  0\n",
       "35  0\n",
       "36  0\n",
       "37  0\n",
       "38  1\n",
       "39  0\n",
       "40  0\n",
       "41  0\n",
       "42  0\n",
       "43  1\n",
       "44  0\n",
       "45  0\n",
       "46  0\n",
       "47  0\n",
       "48  0\n",
       "49  1"
      ]
     },
     "execution_count": 753,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "e6a3ad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4000\n",
    "hidden_size = (2048, 1024, 256)\n",
    "output_size = 4000\n",
    "num_classes = 1\n",
    "learning_rate = 0.0001\n",
    "batch_size = 4000\n",
    "num_epochs = 300\n",
    "class Feedforward(torch.nn.Module):\n",
    "        def __init__(self, input_size, hidden_size):\n",
    "            super(Feedforward, self).__init__()\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "            self.relu = torch.nn.ReLU()\n",
    "            self.fc2 = torch.nn.Linear(self.hidden_size, 1)\n",
    "            self.sigmoid = torch.nn.Sigmoid()\n",
    "        def forward(self, x):\n",
    "            hidden = self.fc1(x)\n",
    "            relu = self.relu(hidden)\n",
    "            output = self.fc2(relu)\n",
    "            output = self.sigmoid(output)\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "50922c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Feedforward(7801, 4000)\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "d4f17819",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (7801x1 and 7801x4000)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18108/518857870.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrain_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_similarity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdev_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev_similarity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mbefore_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdev_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test loss before training'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mbefore_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18108/3512779022.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0mrelu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (7801x1 and 7801x4000)"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "train_tensor = torch.FloatTensor(train_similarity)\n",
    "dev_tensor = torch.FloatTensor(dev_similarity)\n",
    "y_pred = model(train_tensor)\n",
    "before_train = criterion(y_pred.squeeze(), dev_tensor)\n",
    "print('Test loss before training' , before_train.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "8f82e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "        # Define sigmoid activation and softmax output \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of our operations\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "cca99082",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4000\n",
    "hidden_size = [2048, 1024, 512, 128, 64]\n",
    "output_size = 10\n",
    "\n",
    "#model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[2], hidden_sizes[3]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[3], hidden_sizes[4]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[4], output_size),\n",
    "                      nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "9f9f88a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4000\n",
    "hidden_size = [2048, 1024, 512, 128, 64]\n",
    "output_size = 10\n",
    "num_classes = 1\n",
    "learning_rate = 0.0001\n",
    "batch_size = 4000\n",
    "num_epochs = 300\n",
    "class OurNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(OurNet, self).__init__()\n",
    "        self.layer_1 = nn.Linear(input_size,hidden_size[0], bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer_2 = nn.Linear(hidden_size[1], hidden_size[2], bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer_3 = nn.Linear(hidden_size[2], hidden_size[3], bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer_4 = nn.Linear(hidden_size[3], hidden_size[4], bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output_layer = nn.Linear(hidden_size[4], output_size, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer_1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer_2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer_3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer_4(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "a2efe0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = OurNet(input_size, hidden_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "73024202",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "4cfbd363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(training, labels, iterate, batchsize):\n",
    "        i = batchsize*iterate\n",
    "        return training[i:(i+batchsize)], labels[i:(i+batchsize)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "f5bb0f9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (4000x1 and 4000x2048)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18108/4149882751.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m# Forward + Backward + Optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# zero the gradient buffer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18108/3651188599.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (4000x1 and 4000x2048)"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    total_batch = int(len(train_similarity)/batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_x,batch_y = get_batch(train_similarity, train_labels,i,batch_size)\n",
    "        similarity = Variable(torch.FloatTensor(batch_x))\n",
    "        labels = Variable(torch.FloatTensor(batch_y))\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad() # zero the gradient buffer\n",
    "    outputs = net(similarity)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "            %(epoch+1, num_epochs, i+1, len(train_similarity)//batch_size, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b68acca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
